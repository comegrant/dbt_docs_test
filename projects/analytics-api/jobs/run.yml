resources:
  jobs:
    - job_key: analytics_api-run
      name: analytics_api-run-${bundle.target}

      permissions:
        - group_name: data-scientists
          level: CAN_MANAGE_RUN

      job_clusters:
        - job_cluster_key: analytics_api
          new_cluster:
            num_workers: 1
            spark_version: ${var.cluster_version}
            node_type_id: Standard_DS4_v2
            custom_tags:
              user: "Data scientists"
              tool: "Preselector"
              env: ${bundle.target}
              managed_by: "manually"
            docker_image:
              url: "${var.docker_image_url}"
              basic_auth:
                username: "{{ secrets/auth_common/docker-registry-username }}"
                password: "{{ secrets/auth_common/docker-registry-password }}"

      schedule:
        quartz_cron_expression: '0 0 2 ? * MON'
        timezone_id: UTC

      tasks:
        - task_key: run
          job_cluster_key: analytics_api
          notebook_task:
            notebook_path: run.py
            base_parameters:
              environment: "${var.environment}"

        - task_key: run-fail
          depends_on:
          - task_key: run
          run_if: AT_LEAST_ONE_FAILED
          run_job_task:
            job_id: ${var.slack_notification_job_id} #Reads from the variable defined in the databricks.yml file
            job_parameters:
              environment: ${bundle.target} #Reads from the target environment as defined in the databricks.yml file
              header_message: ❌ analytics_api job failed
              body_message: Check Databricks for more details
              is_error: true
              relevant_people: Niladri Banerjee

        - task_key: run-success
          depends_on:
          - task_key: run
          run_if: NONE_FAILED
          run_job_task:
            job_id: ${var.slack_notification_job_id} #Reads from the variable defined in the databricks.yml file
            job_parameters:
              environment: ${bundle.target} #Reads from the target environment as defined in the databricks.yml file
              body_message: ✅ analytics_api job succeeded
              is_error: false
