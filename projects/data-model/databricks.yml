# yaml-language-server: $schema=bundle_config_schema.json

# This file defines the structure of this project and how it is deployed
# to production using Databricks Asset Bundles.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.

bundle:
  name: data-model

include:
  - jobs/*.yml

variables:
  client-id:
    description: The ID of the service Service Principal
    default: 9d48429c-9bb6-4c22-ae63-26095e7aab6f
  warehouse_id:
    description: The id of the sql warehouse used for the dbt task
  slack_notification_job_id:
    description: The id of the slack notification job to call
  running_job_check_job_id:
    description: The id of the running job check job to call
  preselector_materialization_job_id:
    description: The id of the preselector materialization job to call
  ingestion_job_id:
    description: The id of the job that ingests source tables
  copy_from_prod_daily_pause_status:
    description: "Whether the copy_from_prod_daily job should be paused or unpaused."
    default: PAUSED
  databricks_forecasting_sp_application_id:
    description: The id of the databricks forecasting service principal
  dbt_databricks_version:
    description: The version of dbt-databricks to use in all jobs
    default: ">=1.10.0,<1.10.9"

targets:
  dev:
    default: true
    # We use 'mode: development' to indicate this is a personal development copy.
    # Any job schedules and triggers are paused by default.
    mode: development
    variables:
      warehouse_id: 45100b61eb7ee2f5
      slack_notification_job_id: 221967110790300
      running_job_check_job_id: 1013342696672148
      preselector_materialization_job_id: 98557615197253
      ingestion_job_id: 801173944698032
      databricks_forecasting_sp_application_id: c185ec1e-ec85-4a95-9362-cfc489a00039

    resources:
      jobs:
        copy_from_prod_daily:
          schedule:
            pause_status: ${var.copy_from_prod_daily_pause_status}

  test:
    # We want test to be a production-like environment, but with paused jobs.
    # Data in test will be updated by the copy_from_prod_daily job.
    mode: production
    presets:
      trigger_pause_status: PAUSED
    variables:
      warehouse_id: 76c581aa18fb7b4f
      slack_notification_job_id: 823927532277018
      running_job_check_job_id: 151995008710777
      preselector_materialization_job_id: 1030627407532831
      ingestion_job_id: 510861596863971
      databricks_forecasting_sp_application_id: b75a37c9-53e9-4b66-a44d-2e3e03e3dbb0
    resources:
      jobs:
        copy_from_prod_daily:
          schedule:
            pause_status: ${var.copy_from_prod_daily_pause_status}

  prod:
    mode: production
    variables:
      warehouse_id: 1a2fc265706df5fb
      slack_notification_job_id: 808732355997444
      running_job_check_job_id: 497656932586919
      preselector_materialization_job_id: 148734131753684
      ingestion_job_id: 488661079691855
      databricks_forecasting_sp_application_id: e91b18b8-e2c8-468d-bb1b-6bd194b7bf6c
    resources:
      jobs:
        copy_from_prod_daily:
          schedule:
            pause_status: ${var.copy_from_prod_daily_pause_status}
