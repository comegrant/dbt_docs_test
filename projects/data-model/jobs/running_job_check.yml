#Checks if a specified job is running. Fails if the job is running, succeeds if it's not running. Use this as a dependency check in other jobs.
resources:
  jobs:
    running_job_check:
      name: running-job-check

      tags:
        tool: "data platform"
        env: ${bundle.target}
        managed_by: "manually"

      timeout_seconds: 300  # 5 minutes timeout
      edit_mode: EDITABLE

      environments:
        - environment_key: running-job-check-default
          spec:
            client: "1"

      tasks:
        - task_key: check-job-status
          spark_python_task:
            python_file: ../useful/running_job_check.py
            parameters:
              - --job_name
              - "{{job.parameters.job_name}}"
              - --environment
              - "{{job.parameters.environment}}"
          environment_key: running-job-check-default

      parameters:
        - name: job_name
          default: "add the job name you want to check for here"
        - name: environment
          default: ${bundle.target}
