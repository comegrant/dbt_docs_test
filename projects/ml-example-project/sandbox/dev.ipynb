{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.train.train import Args\n",
    "args = Args(\n",
    "    company=\"GL\",\n",
    "    env=\"dev\",\n",
    "    is_run_on_databricks=False,\n",
    "    is_use_feature_store=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.db import get_spark_session\n",
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.train.configs import get_company_train_configs\n",
    "from constants.companies import get_company_by_code\n",
    "company_train_configs = get_company_train_configs(company_code=args.company)\n",
    "company_properties = get_company_by_code(company_code=args.company)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.train.data import create_training_set\n",
    "from ml_example_project.train.configs import feature_lookup_config_list\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "# Get training data\n",
    "if (args.is_run_on_databricks) & (args.is_use_feature_store):\n",
    "    fe = FeatureEngineeringClient()\n",
    "else:\n",
    "    fe = None\n",
    "    # Override it if set to True.\n",
    "    # It can't be used unless you are running on Databricks\n",
    "    args.is_use_feature_store = False\n",
    "\n",
    "training_set = create_training_set(\n",
    "    spark=spark,\n",
    "    company_id=company_properties.company_id,\n",
    "    feature_lookup_config_list=feature_lookup_config_list,\n",
    "    company_train_configs=company_train_configs,\n",
    "    fe=fe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.is_use_feature_store:\n",
    "    df_training = training_set.load_df().toPandas()\n",
    "else:\n",
    "    df_training = training_set.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An very minimal EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Create the scatter plot\n",
    "fig = px.histogram(\n",
    "    df_training,\n",
    "    x=\"number_of_recipe_steps\",\n",
    "    color=\"recipe_difficulty_level_id\",\n",
    "    title=\"Cooking Time vs Recipe Difficulty Level\",\n",
    "    labels={\"cooking_time_to\": \"Cooking Time (to)\", \"recipe_difficulty_level_id\": \"Recipe Difficulty Level ID\"}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target = \"recipe_difficulty_level_id\"\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df_training.drop(columns=[target]),\n",
    "    df_training[target],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.train.preprocessor import PreProcessor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "preprocessor = PreProcessor(\n",
    "    numeric_features=[\"number_of_ingredients\",  \"number_of_taxonomies\"],\n",
    "    categorical_features=[\"cooking_time_from\"]\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    **company_train_configs.model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.train.model import ClassificationPipeline\n",
    "pipeline = ClassificationPipeline(\n",
    "    preprocessor=preprocessor,\n",
    "    model=rf,\n",
    "    task=\"classify\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(model_input=X_val, context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true=y_val, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the big wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.train.train import Args, train_model\n",
    "\n",
    "args = Args(company=\"AMK\", env=\"dev\", is_run_on_databricks=False)\n",
    "train_model(args=args, spark=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(f\"databricks://{args.profile_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = 'runs:/d69a11fda38b434aaec4db2377fb2cea/test'\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.predict.data import create_predict_dataframe\n",
    "df_predict_pk, predict_data = create_predict_dataframe(\n",
    "    spark=spark,\n",
    "    company_id=company_properties.company_id,\n",
    "    predict_start_yyyyww=202450,\n",
    "    predict_end_yyyyww=202451,\n",
    "    is_use_feature_store= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(predict_data.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_predict_pk.toPandas()\n",
    "df_result[\"recipe_difficulty_level_id_prediction\"] = y_pred\n",
    "spark_df_result = spark.createDataFrame(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_example_project.db import save_outputs\n",
    "save_outputs(\n",
    "    spark_df=spark_df_result,\n",
    "    table_name=\"ml_example_project_predictions\",\n",
    "    table_schema=\"mloutputs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
