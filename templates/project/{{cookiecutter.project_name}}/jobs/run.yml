resources:
  jobs:
    {{cookiecutter.project_name}}-run:
      name: {{cookiecutter.project_name}}-run-${bundle.target}

      permissions:
        - group_name: data-scientists
          level: CAN_MANAGE_RUN

      parameters:
        - name: environment
          default: "${var.environment}"
        - name: table
          default: "mloutputs.attribute_scoring"

      job_clusters:
        - job_cluster_key: {{cookiecutter.project_name}}
          new_cluster:
            num_workers: 1
            spark_version: ${var.cluster_version}
            node_type_id: Standard_DS4_v2
            custom_tags:
              user: "Data scientists"
              tool: "{{cookiecutter.project_name}}"
              env: ${bundle.target}
              managed_by: "manually"
            docker_image:
              url: "${var.docker_image_url}"
              basic_auth:
                username: "{{"{{"}}secrets/auth_common/docker-registry-username{{"}}"}}"
                password: "{{"{{"}}secrets/auth_common/docker-registry-password{{"}}"}}"

      schedule:
        quartz_cron_expression: '0 0 2 ? * MON'
        timezone_id: UTC

      tasks:
        - task_key: run
          job_cluster_key: {{cookiecutter.project_name}}
          spark_python_task:
            python_file: run.py
            parameters:
              - "--environment"
              - "{{"{{"}}job.parameters.environment{{"}}"}}"
              - "--table"
              - "{{"{{"}}job.parameters.table{{"}}"}}"

        - task_key: run-fail
          depends_on:
          - task_key: run
          run_if: AT_LEAST_ONE_FAILED
          run_job_task:
            job_id: ${var.slack_notification_job_id} # Reads from the variable defined in the databricks.yml file
            job_parameters:
              environment: ${bundle.target} # Reads from the target environment as defined in the databricks.yml file
              header_message: ❌ {{cookiecutter.project_name}} job failed
              body_message: Check Databricks for more details
              is_error: true
              relevant_people: {{cookiecutter.owner_full_name}}

        - task_key: run-success
          depends_on:
          - task_key: run
          run_if: NONE_FAILED
          run_job_task:
            job_id: ${var.slack_notification_job_id} # Reads from the variable defined in the databricks.yml file
            job_parameters:
              environment: ${bundle.target} # Reads from the target environment as defined in the databricks.yml file
              body_message: ✅ {{cookiecutter.project_name}} job succeeded
              is_error: false
